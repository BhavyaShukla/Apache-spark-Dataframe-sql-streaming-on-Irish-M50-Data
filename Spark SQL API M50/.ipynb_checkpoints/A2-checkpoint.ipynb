{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Irish M50 Dataset\n",
    "# Predefined values  and Import Statements \n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.getOrCreate()\n",
    "df = spark.read.csv('/home/bhavyamilanshukla/per-vehicle-records-2020-01-31.csv',\n",
    "inferSchema = True, header = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "m50=[15012,15011,15010,1507,1506,1505,1504,1509,1503,1508,1502,1501,1500,1012]\n",
    "\n",
    "\n",
    "df.registerTempTable(\"vehicle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+--------------------+\n",
      "|classname|  count|          percentage|\n",
      "+---------+-------+--------------------+\n",
      "|      CAR|3804948|   80.25858594040197|\n",
      "|      LGV| 530714|  11.194464465420944|\n",
      "|  HGV_ART| 208477|   4.397450167807071|\n",
      "|  HGV_RIG| 129477|  2.7310861887745705|\n",
      "|      BUS|  32575|  0.6871114761643508|\n",
      "|  CARAVAN|  20344| 0.42912036442325563|\n",
      "|    MBIKE|  13979| 0.29486205142905475|\n",
      "|     null|    347|0.007319345578788326|\n",
      "+---------+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "#  1 Calculate the usage of Irish road network in terms of percentage grouped by vehicle category\n",
    "q1 = spark.sql(\"select classname, count(class) as count, count(class)*100/(select count(*) from vehicle) as percentage from vehicle group by classname, class order by count desc\")\n",
    "q1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1.select('classname','count','percentage')\\\n",
    ".write.format('org.apache.spark.sql.cassandra')\\\n",
    ".options(table='q1',keyspace='assignment2')\\\n",
    ".save(mode='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------------+\n",
      "|  count|classname|  percentage|\n",
      "+-------+---------+------------+\n",
      "| 208477|  HGV_ART|     4.39745|\n",
      "|3804948|      CAR|    80.25858|\n",
      "|  20344|  CARAVAN|  0.42912036|\n",
      "|    347|     null|0.0073193456|\n",
      "|  32575|      BUS|   0.6871115|\n",
      "|  13979|    MBIKE|  0.29486206|\n",
      "| 530714|      LGV|   11.194465|\n",
      "| 129477|  HGV_RIG|   2.7310863|\n",
      "+-------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format('org.apache.spark.sql.cassandra')\\\n",
    ".load(keyspace='assignment2',table='q1').show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+\n",
      "|hour|vehiclecount|\n",
      "+----+------------+\n",
      "|   7|       67199|\n",
      "|  14|       66812|\n",
      "|   8|       65832|\n",
      "|  16|       65370|\n",
      "|  17|       59487|\n",
      "|  12|       56581|\n",
      "|   9|       55841|\n",
      "|  10|       53002|\n",
      "|  13|       51568|\n",
      "|  18|       51192|\n",
      "|  11|       47798|\n",
      "|   6|       42262|\n",
      "|  15|       40698|\n",
      "|  19|       39545|\n",
      "|  20|       30234|\n",
      "|  21|       21773|\n",
      "|  22|       16428|\n",
      "|   5|       12235|\n",
      "|  23|       12063|\n",
      "|   0|        5811|\n",
      "+----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 2\n",
    "# 2. Calculate the highest and lowest hourly Fows on M50 - show the hours and total number of vehicle counts.\n",
    "m50_fltr= df.filter(df.cosit.isin(m50))\n",
    "m50_fltr.registerTempTable(\"m50_fltr\")\n",
    "q2=spark.sql('select hour, count(class) as vehiclecount from m50_fltr group by hour order by vehiclecount desc')\n",
    "q2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2.select('hour','vehiclecount')\\\n",
    ".write.format('org.apache.spark.sql.cassandra')\\\n",
    ".options(table='q2',keyspace='assignment2')\\\n",
    ".save(mode='append')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+\n",
      "|hour|vehiclecount|\n",
      "+----+------------+\n",
      "|   9|       55841|\n",
      "|  14|       66812|\n",
      "|  21|       21773|\n",
      "|  17|       59487|\n",
      "|  12|       56581|\n",
      "|   3|        2530|\n",
      "|   4|        5604|\n",
      "|  18|       51192|\n",
      "|  15|       40698|\n",
      "|  22|       16428|\n",
      "|  20|       30234|\n",
      "|   7|       67199|\n",
      "|   6|       42262|\n",
      "|   5|       12235|\n",
      "|  10|       53002|\n",
      "|  16|       65370|\n",
      "|  13|       51568|\n",
      "|  11|       47798|\n",
      "|   1|        2890|\n",
      "|  19|       39545|\n",
      "+----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format('org.apache.spark.sql.cassandra')\\\n",
    ".load(keyspace='assignment2',table='q2').show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+-----------+\n",
      "|hour|vehiclecount|Time_Of_Day|\n",
      "+----+------------+-----------+\n",
      "|   6|       42262|    Morning|\n",
      "|   7|       67199|    Morning|\n",
      "|   8|       65832|    Morning|\n",
      "|   9|       55841|    Morning|\n",
      "|  10|       53002|    Morning|\n",
      "+----+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Question 3a\n",
    "# 3. Calculate the evening and morning rush hours on M50 - show the hours and the total counts.\n",
    "# Morning\n",
    "q3a = spark.sql('select hour, count(class) as vehiclecount, \"Morning\" as Time_Of_Day from m50_fltr where hour between 6 and 10  group by hour order by hour') \n",
    "q3a.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3a.select('hour','vehiclecount','time_of_day')\\\n",
    ".write.format('org.apache.spark.sql.cassandra')\\\n",
    ".options(table='q3a',keyspace='assignment2')\\\n",
    ".save(mode='append')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+------------+\n",
      "|hour|time_of_day|vehiclecount|\n",
      "+----+-----------+------------+\n",
      "|   9|    Morning|       55841|\n",
      "|   7|    Morning|       67199|\n",
      "|   6|    Morning|       42262|\n",
      "|  10|    Morning|       53002|\n",
      "|   8|    Morning|       65832|\n",
      "+----+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format('org.apache.spark.sql.cassandra')\\\n",
    ".load(keyspace='assignment2',table='q3a').show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+-----------+\n",
      "|hour|vehiclecount|time_of_day|\n",
      "+----+------------+-----------+\n",
      "|  16|       65370|    Evening|\n",
      "|  17|       59487|    Evening|\n",
      "|  18|       51192|    Evening|\n",
      "|  19|       39545|    Evening|\n",
      "|  20|       30234|    Evening|\n",
      "+----+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Question 3b\n",
    "# 3. Calculate the evening and morning rush hours on M50 - show the hours and the total counts.\n",
    "# Evening\n",
    "q3b = spark.sql('select hour, count(class) as vehiclecount, \"Evening\" as time_of_day from m50_fltr where hour between 16 and 20 group by hour order by hour')\n",
    "q3b.show() \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3b.select('hour','vehiclecount','time_of_day')\\\n",
    ".write.format('org.apache.spark.sql.cassandra')\\\n",
    ".options(table='q3b',keyspace='assignment2')\\\n",
    ".save(mode='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+------------+\n",
      "|hour|time_of_day|vehiclecount|\n",
      "+----+-----------+------------+\n",
      "|  17|    Evening|       59487|\n",
      "|  18|    Evening|       51192|\n",
      "|  20|    Evening|       30234|\n",
      "|  16|    Evening|       65370|\n",
      "|  19|    Evening|       39545|\n",
      "+----+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format('org.apache.spark.sql.cassandra')\\\n",
    ".load(keyspace='assignment2',table='q3b').show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----------------+\n",
      "| junction|cosit|     averagespeed|\n",
      "+---------+-----+-----------------+\n",
      "|Jn13-Jn14| 1507|99.00845921450151|\n",
      "|Jn14-Jn15|15010|97.81252274326192|\n",
      "|Jn15-Jn16|15011|97.19775581634754|\n",
      "|Jn16-Jn17|15012|93.78990503959967|\n",
      "|Jn12-Jn13| 1506|90.89604001118734|\n",
      "|Jn05-Jn06| 1502|87.70600667675384|\n",
      "|Jn04-Jn05| 1501|87.25861183179634|\n",
      "|Jn11-Jn12| 1505|85.31515519064502|\n",
      "|Jn10-Jn11| 1504|84.48510440700593|\n",
      "|Jn06-Jn07| 1508|82.67599094114848|\n",
      "|Jn07-Jn09| 1503| 81.0891341051616|\n",
      "|Jn03-Jn04| 1500| 79.3267028425403|\n",
      "|Jn02-Jn03| 1012| 78.5138596978229|\n",
      "|Jn09-Jn10| 1509|78.43267256357605|\n",
      "+---------+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Question 4\n",
    "# 4. Calculate average speed between each junction on M50 (e.g., junction 1 - junction2, junction 2 - junction 3, etc.). \n",
    "q4=spark.sql(\"\"\"SELECT CASE  \n",
    "             WHEN cosit=1012 THEN \"Jn02-Jn03\"   \n",
    "             WHEN cosit=1500 THEN \"Jn03-Jn04\" \n",
    "             WHEN cosit=1501 THEN \"Jn04-Jn05\"\n",
    "             WHEN cosit=1502 THEN \"Jn05-Jn06\"  \n",
    "             WHEN cosit=1503 THEN \"Jn07-Jn09\"  \n",
    "             WHEN cosit=1504 THEN \"Jn10-Jn11\" \n",
    "             WHEN cosit=1505 THEN \"Jn11-Jn12\"  \n",
    "             WHEN cosit=1506 THEN \"Jn12-Jn13\" \n",
    "             WHEN cosit=1507 THEN \"Jn13-Jn14\" \n",
    "             WHEN cosit=1508 THEN \"Jn06-Jn07\"\n",
    "             WHEN cosit=1509 THEN \"Jn09-Jn10\"\n",
    "             WHEN cosit=15010 THEN \"Jn14-Jn15\" \n",
    "             WHEN cosit=15011 THEN \"Jn15-Jn16\"   \n",
    "             WHEN cosit=15012 THEN \"Jn16-Jn17\"  \n",
    "             ELSE \"OTHERS\"            \n",
    "             end as junction,      \n",
    "             cosit,                 \n",
    "             avg(speed) as averagespeed \n",
    "             from m50_fltr          \n",
    "             group by junction, cosit\n",
    "             order by averagespeed desc\"\"\" )\n",
    "q4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4.select('junction','cosit','averagespeed')\\\n",
    ".write.format('org.apache.spark.sql.cassandra')\\\n",
    ".options(table='q4',keyspace='assignment2')\\\n",
    ".save(mode='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+---------+\n",
      "|cosit|averagespeed| junction|\n",
      "+-----+------------+---------+\n",
      "| 1501|    87.25861|Jn04-Jn05|\n",
      "|15010|    97.81252|Jn14-Jn15|\n",
      "| 1509|    78.43267|Jn09-Jn10|\n",
      "| 1502|    87.70601|Jn05-Jn06|\n",
      "| 1507|    99.00846|Jn13-Jn14|\n",
      "| 1508|    82.67599|Jn06-Jn07|\n",
      "|15011|   97.197754|Jn15-Jn16|\n",
      "| 1504|    84.48511|Jn10-Jn11|\n",
      "| 1506|    90.89604|Jn12-Jn13|\n",
      "|15012|     93.7899|Jn16-Jn17|\n",
      "| 1503|   81.089134|Jn07-Jn09|\n",
      "| 1012|    78.51386|Jn02-Jn03|\n",
      "| 1505|   85.315155|Jn11-Jn12|\n",
      "| 1500|   79.326706|Jn03-Jn04|\n",
      "+-----+------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format('org.apache.spark.sql.cassandra')\\\n",
    ".load(keyspace='assignment2',table='q4').show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+---------+\n",
      "|      location| cosit|hgv_count|\n",
      "+--------------+------+---------+\n",
      "|          Test|   997|    11986|\n",
      "|   Castleknock|  1508|     9630|\n",
      "|      Donabate|  1015|     9462|\n",
      "|       Kilteel|200723|     8977|\n",
      "|       Finglas|  1502|     7922|\n",
      "|      Ballymun|  1501|     7145|\n",
      "|   Palmerstown|  1503|     6938|\n",
      "|     Kingswood|  1071|     6259|\n",
      "|Newlands Cross|  1070|     5850|\n",
      "|  VMS Citywest|  1073|     5846|\n",
      "+--------------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Question 5\n",
    "# 5. Calculate the top 10 locations with highest number of counts of HGVs (class). Map the COSITs with their names given on the map.\n",
    "q5=spark.sql(\"\"\"SELECT                       \n",
    "                CASE                     \n",
    "                WHEN cosit=997 THEN \"Test\"    \n",
    "                WHEN cosit=1508 THEN \"Castleknock\"   \n",
    "                WHEN cosit=1015 THEN \"Donabate\"       \n",
    "                WHEN cosit=200723 THEN \"Kilteel\"     \n",
    "                WHEN cosit=1502 THEN \"Finglas\"      \n",
    "                WHEN cosit=1501 THEN \"Ballymun\"     \n",
    "                WHEN cosit=1503 THEN \"Palmerstown\"  \n",
    "                WHEN cosit=1071 THEN \"Kingswood\"    \n",
    "                WHEN cosit=1070 THEN \"Newlands Cross\" \n",
    "                WHEN cosit=1073 THEN \"VMS Citywest\"    \n",
    "                ELSE \"OTHERS\"                        \n",
    "                end as location,              \n",
    "                cosit,        \n",
    "                count(class) as hgv_count \n",
    "                from  vehicle\n",
    "                Where classname in ('HGV_ART', 'HGV_RIG')   \n",
    "                group by location, cosit  \n",
    "                order by hgv_count desc  \n",
    "                limit(10)               \n",
    "                \"\"\")\n",
    "q5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "q5.select('location','cosit','hgv_count')\\\n",
    ".write.format('org.apache.spark.sql.cassandra')\\\n",
    ".options(table='q5',keyspace='assignment2')\\\n",
    ".save(mode='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------------+\n",
      "| cosit|hgv_count|      location|\n",
      "+------+---------+--------------+\n",
      "|  1501|     7145|      Ballymun|\n",
      "|  1502|     7922|       Finglas|\n",
      "|200723|     8977|       Kilteel|\n",
      "|  1071|     6259|     Kingswood|\n",
      "|  1508|     9630|   Castleknock|\n",
      "|  1070|     5850|Newlands Cross|\n",
      "|  1073|     5846|  VMS Citywest|\n",
      "|  1503|     6938|   Palmerstown|\n",
      "|  1015|     9462|      Donabate|\n",
      "|   997|    11986|          Test|\n",
      "+------+---------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format('org.apache.spark.sql.cassandra')\\\n",
    ".load(keyspace='assignment2',table='q5').show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
